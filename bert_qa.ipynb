{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, AutoTokenizer\n",
    "\n",
    "max_len = 256\n",
    "configuration = BertConfig()  # default parameters and configuration for BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the slow pretrained tokenizer\n",
    "# slow_tokenizer = BertTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "# save_path = \"phobert-base/\"\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "# slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(\"phobert-base/vocab.txt\", lowercase=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "# train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
    "# eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n",
    "# eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)\n",
    "train_path = \"./train_qa_1654_empty_ans.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98155 training points created.\n",
      "10659 evaluation points created.\n"
     ]
    }
   ],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.all_answers = all_answers\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer_text = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "        if end_char_idx >= len(context):\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "#         print(tokenized_context.offsets)\n",
    "\n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "#         print(ans_token_idx)\n",
    "\n",
    "        if len(ans_token_idx) == 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        padding_length = max_len - len(input_ids)\n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "\n",
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "    raw_eval_data = {\"data\": raw_train_data[\"data\"][600:]}\n",
    "    raw_train_data = {\"data\": raw_train_data[\"data\"][:600]}\n",
    "#     raw_train_data = {\"data\": raw_train_data[\"data\"][:10]}\n",
    "#     raw_train_data = {\"data\": [\n",
    "#                               {\"title\": \"University_of_Notre_Dame\", \n",
    "#                                \"paragraphs\": [\n",
    "#                                                {\"context\": \"Chelsea cần chiến thắng trước Stoke City ở Stamford Bridge để cân bằng kỷ lục 13 chiến thắng của Arsenal ở cuối mùa 2001/02. Cuối cùng, đoàn quân của HLV Conte đã hoàn thành nhiệm vụ này khi vượt qua đối thủ với tỷ số 4-2.\", \n",
    "#                                                 \"qas\": [\n",
    "#                                                         {\"answers\": [{\"answer_start\": 0, \"text\": \"Chelsea\"}, {\"answer_start\": 30, \"text\": \"Stoke City\"}], \n",
    "#                                                          \"question\": \"Team?\"},\n",
    "#                                                         {\"answers\": [{\"answer_start\": 30, \"text\": \"Stoke City\"}, {\"answer_start\": 0, \"text\": \"Chelsea\"}], \n",
    "#                                                          \"question\": \"Team?\"}\n",
    "#                                                         ]\n",
    "#                                                }\n",
    "#                                             ]\n",
    "#                               }\n",
    "#                               ]\n",
    "#                      }\n",
    "\n",
    "# with open(eval_path) as f:\n",
    "#     raw_eval_data = json.load(f)\n",
    "#     raw_eval_data = {\"data\": raw_eval_data[\"data\"][:5]}\\\n",
    "#     raw_eval_data = {\"data\": [\n",
    "#                               {\"title\": \"University_of_Notre_Dame\", \n",
    "#                                \"paragraphs\": [\n",
    "#                                                {\"context\": \"Chelsea cần chiến thắng trước Stoke City ở Stamford Bridge để cân bằng kỷ lục 13 chiến thắng của Arsenal ở cuối mùa 2001/02. Cuối cùng, đoàn quân của HLV Conte đã hoàn thành nhiệm vụ này khi vượt qua đối thủ với tỷ số 4-2.\", \n",
    "#                                                 \"qas\": [\n",
    "#                                                         {\"answers\": [{\"answer_start\": 0, \"text\": \"Chelsea\"}, {\"answer_start\": 30, \"text\": \"Stoke City\"}], \n",
    "#                                                          \"question\": \"Team?\"},\n",
    "#                                                     {\"answers\": [{\"answer_start\": 30, \"text\": \"Stoke City\"}, {\"answer_start\": 0, \"text\": \"Chelsea\"}], \n",
    "#                                                          \"question\": \"Team?\"},\n",
    "#                                                     {\"answers\": [{\"answer_start\": 0, \"text\": \"Chelsea\"}, {\"answer_start\": 30, \"text\": \"Stoke City\"}], \n",
    "#                                                          \"question\": \"Team?\"}\n",
    "#                                                         ]\n",
    "#                                                }\n",
    "#                                             ]\n",
    "#                               }\n",
    "#                               ]\n",
    "#                      }\n",
    "\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "#                 print(qa)\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                squad_eg = SquadExample(\n",
    "                    question, context, start_char_idx, answer_text, all_answers\n",
    "                )\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = [\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"],\n",
    "    ]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
    "# print(x_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    ## BERT encoder\n",
    "    encoder = TFBertModel.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "    ## QA Model\n",
    "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    embedding = encoder(\n",
    "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
    "    )[0]\n",
    "\n",
    "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
    "    start_logits = layers.Flatten()(start_logits)\n",
    "\n",
    "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
    "    end_logits = layers.Flatten()(end_logits)\n",
    "\n",
    "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
    "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs=[input_ids, token_type_ids, attention_mask],\n",
    "        outputs=[start_probs, end_probs],\n",
    "    )\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
    "    model.compile(optimizer=optimizer, loss=[loss, loss])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at vinai/phobert-base were not used when initializing TFBertModel: ['roberta', 'lm_head']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['bert']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   ((None, 256, 768), ( 134998272   input_4[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_logit (Dense)             (None, 256, 1)       768         tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "end_logit (Dense)               (None, 256, 1)       768         tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           start_logit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           end_logit[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256)          0           flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 134,999,808\n",
      "Trainable params: 134,999,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "use_tpu = False\n",
    "if use_tpu:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    exclude = set(string.punctuation)\n",
    "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    # Remove articles\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    text = re.sub(regex, \" \", text)\n",
    "\n",
    "    # Remove extra white space\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "class ExactMatch(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Each `SquadExample` object contains the character level offsets for each token\n",
    "    in its input paragraph. We use them to get back the span of text corresponding\n",
    "    to the tokens between our predicted start and end tokens.\n",
    "    All the ground-truth answers are also present in each `SquadExample` object.\n",
    "    We calculate the percentage of data points where the span of text obtained\n",
    "    from model predictions matches one of the ground-truth answers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "\n",
    "            normalized_pred_ans = normalize_text(pred_ans)\n",
    "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./ckpt/checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode=\"min\",\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1750/2002 [=========================>....] - ETA: 1:08 - loss: 1.1236 - activation_6_loss: 0.5646 - activation_7_loss: 0.5590"
     ]
    }
   ],
   "source": [
    "exact_match_callback = ExactMatch(x_eval, y_eval)\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,  # For demonstration, 3 epochs are recommended\n",
    "    batch_size=8,\n",
    "    callbacks=[exact_match_callback, model_checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./ckpt/checkpoint\")\n",
    "res = model.predict(x_eval)\n",
    "print(np.array(res).shape)\n",
    "\n",
    "idy, idx, idz = np.where(np.array(res) > 0.1)\n",
    "index = np.array([idx, idy, idz])\n",
    "\n",
    "list_answer = []\n",
    "for x in set(sorted(idx)):\n",
    "    ques_idx = np.where(index[0] == x)    \n",
    "    start_idx = np.where(index[1] == 0)\n",
    "    end_idx = np.where(index[1] == 1)\n",
    "\n",
    "    list_start = np.intersect1d(ques_idx, start_idx)\n",
    "    list_end = np.intersect1d(ques_idx, end_idx)\n",
    "    \n",
    "    answers = [(index[2][pair[0]], index[2][pair[1]]) for pair in zip(list_start, list_end)]\n",
    "    list_answer.append(answers)\n",
    "    \n",
    "print(list_answer)\n",
    "        \n",
    "\n",
    "#     a = np.where(idy[ques_idx] == 0)\n",
    "#     print(idy[ques_idx][a])\n",
    "    \n",
    "#     b = np.where(idy[ques_idx] == 1)\n",
    "#     print(idy[ques_idx][b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
